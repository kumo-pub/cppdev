# Apache Avro
**类型**：行式、基于schema的序列化格式

## 概述
Apache Avro 是一种**面向行的序列化系统**，专为高效数据序列化、RPC通信和流式处理设计。与 Parquet 或 Arrow 等列式格式不同，Avro 按行存储记录，使其在写密集型工作负载、流式摄入和行级操作场景中表现最优。

Avro 依赖**schema（模式）** 定义数据结构，且 schema 会**与数据一同存储**，支持自描述文件，并能在不破坏兼容性的前提下实现 schema 进化。

## 核心特性
- **行式存储**：每条记录连续写入，支持快速写入和行级访问
- **基于schema**：所有 Avro 数据必须遵循 JSON 格式的 schema，读取端可自动处理缺失字段或进化后的 schema
- **动态schema进化**：支持添加、删除或修改字段，具备向前/向后兼容性
- **数据类型**：支持基本类型（int、long、float、double、string、bytes）、复杂类型（记录、数组、映射、联合、枚举、固定长度类型）
- **序列化/RPC**：原生支持二进制编码、JSON编码，可与 RPC 框架无缝集成
- **压缩支持**：内置 `deflate`、`snappy` 等压缩编解码器，适用于磁盘存储

## 性能考量
- **写入吞吐量**：优化用于仅追加或流式场景下的顺序写入
- **读取性能**：行级访问效率高；与列式格式相比，在分析型工作负载中缓存友好性较弱
- **压缩表现**：二进制编码减小文件体积；`snappy` 编解码器在速度与压缩比之间取得良好平衡

### 示例基准测试
| 操作 | Avro（二进制编码） | JSON | 说明 |
|------|--------------------|------|------|
| 写入 1000万行×10列数据 | 约 1.2 秒 | 约 15 秒 | 二进制编码显著提升吞吐量 |
| 读取 1000万行×10列数据 | 约 0.9 秒 | 约 12 秒 | 行式存储更适配流式场景 |

> 基准测试结果因 JVM/Python/C++ 实现及压缩编解码器不同而异。

## 集成场景与应用
- **流式摄入**：Kafka、Flink 等流处理系统常使用 Avro 进行消息序列化
- **数据流水线**：适用于写密集型 ETL 任务，尤其当行级原子性至关重要时
- **RPC 通信**：schema 进化特性使 Avro 适合消息结构动态变化的长期运行服务
- **数据存储**：用于紧凑、自描述的二进制文件存储，尤其适合 schema 频繁进化的场景

## 运维注意事项
- **schema 管理**：生产环境流水线需部署 schema 注册中心（如 Confluent Schema Registry）
- **文件分片**：Avro 文件支持分片，这对 Hadoop、Spark 等并行处理框架至关重要
- **压缩权衡**：`snappy` 速度快，`deflate` 压缩比更高但占用更多 CPU 资源
- **流式 vs 批处理**：Avro 擅长流式场景；大规模数据集的分析查询建议使用 Parquet 等列式格式

## 参考资料
- [Apache Avro 官方文档](https://avro.apache.org/)
- [Avro 二进制编码规范](https://avro.apache.org/docs/current/spec.html#Binary_encoding)
