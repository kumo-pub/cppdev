# 数据格式概述
本文档全面概述了大规模分析与存储系统中常用的数据格式，包括其典型应用场景、核心库及实现差异，核心聚焦**实用参考**，不涉及技术选型推荐。

## 格式汇总表

| 格式/类型 | 用途/定位 | 典型应用场景 | 核心库/SDK |
|-----------|-----------|--------------|------------|
| **Parquet** | 优化分析场景的列式存储格式 | 大数据分析、ETL流水线、OLAP查询 | Apache Parquet（C++/Java/Python）、Arrow |
| **Arrow** | 面向快速计算的内存中列式格式 | 内存中分析、引擎间零拷贝数据交换 | Apache Arrow（C++/Python/Java/Go） |
| **Avro** | 支持Schema进化的行式存储格式 | 日志存储、流式流水线、数据序列化 | Apache Avro（C++/Java/Python） |
| **HDF5** | 存储大型数值型数据集的分层文件格式 | 科学计算、大型多维数组存储 | HDF5（C/C++/Python）、h5py |
| **NPY** | NumPy数组专用二进制格式 | 机器学习实验、数值型数据存储 | NumPy（Python） |
| **OCR** | 扫描文档专用格式（文本提取场景） | 文档处理流水线、基于OCR的索引构建 | Tesseract、OpenCV、自定义SDK |
| **Substrait** | 关系代数查询计划序列化格式 | 引擎间查询计划交换、查询联邦 | Substrait（基于Protobuf）、Arrow集成 |

## 实现差异与性能说明

### Parquet
- 列式存储支持高效压缩与谓词下推。
- **实现方案**：
- **Apache Parquet C++（Arrow集成版）**——高性能、零拷贝读取，广泛应用于Spark、Dask等分析引擎。
- **Apache Parquet Java**——Hadoop/Spark生态的参考实现；JVM开销可能影响吞吐量。
- **第三方库**——例如Python的fastparquet，默认编解码器与性能表现有所不同。
- **性能考量**：
- 编码/压缩编解码器（Snappy、ZSTD、GZIP）对I/O和CPU占用影响显著。
- 与Arrow集成支持零拷贝内存访问，降低分析流水线的CPU负载。
- C++/Arrow版本支持多线程读取/解压缩，Java默认版本支持较弱。
- **应用场景**：优化用于批处理分析；库的选择对读取吞吐量和CPU消耗影响较大。

### Arrow
- 专注于**内存中分析**，常作为引擎间数据交换的中间格式。
- C++核心实现性能最优；Python/Java绑定可能带来额外开销。

### Avro
- 行式存储，适用于写密集型流式工作负载。
- Java实现最成熟；C++/Python绑定已存在，但部分Schema进化特性可能缺失。
- 性能差异主要体现在序列化/反序列化速度上。

### HDF5
- 分层存储结构，支持丰富元数据，适配大型数值型数据集。
- 核心为C库；Python的`h5py`是其封装库。
- 性能表现极大依赖于分块策略和I/O模式。

### NPY
- 简单高效的NumPy数组二进制存储格式。
- 无默认压缩；优化用于中小型数组。
- 主要用于机器学习实验，不适合生产级批处理存储。

### OCR
- 应用场景专用格式；文本提取精度、速度及输出格式因库而异。
- 无标准化存储方案；使用方式取决于具体文档处理流水线。

### Substrait
- 用于查询计划序列化的协议级格式，不用于原始数据存储。
- 实现差异较小；核心关注点为兼容性和表达能力。

---

:::warning
**注意**：受生态系统限制，每种格式的可选实现方案相对固定。若有额外需求，可基于具体场景定制专属实现。
:::
