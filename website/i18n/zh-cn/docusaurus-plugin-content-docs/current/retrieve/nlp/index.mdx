# NLP Modules for Text Preprocessing

### Overview

In NLP pipelines, preprocessing Chinese and multilingual text efficiently is critical. The following modules provide **tokenization, normalization, and conversion capabilities**, covering most industrial use cases in search, recommendation, and analytics systems.

---

### Module Comparison

| Module            | Functionality                       | Language Support                   | Industrial Fit                             | Notes                                        |
| ----------------- | ----------------------------------- | ---------------------------------- | ------------------------------------------ | -------------------------------------------- |
| **Jieba**         | Chinese word segmentation           | Simplified / Traditional           | ✔️ NLP preprocessing, search indexing      | Dictionary + HMM segmentation, custom words  |
| **Hadar**         | Simplified ↔ Traditional conversion | Chinese (Simplified / Traditional) | ✔️ Text normalization, batch conversion    | Rule-driven, static dictionaries             |
| **SentencePiece** | Subword tokenization                | Multilingual / Unicode             | ✔️ Neural models, large-scale tokenization | BPE / Unigram LM, deterministic tokenization |

---

### Recommendation

* Use **Jieba** for Chinese word segmentation in offline or online NLP pipelines.
* Use **Hadar** for deterministic conversion between Simplified and Traditional Chinese.
* Use **SentencePiece** for subword tokenization in neural network preprocessing or multilingual corpora.
