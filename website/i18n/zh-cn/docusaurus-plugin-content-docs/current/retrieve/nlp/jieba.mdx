# Jieba – Chinese Word Segmentation

- **Project:**
    * [Jieba GitHub](https://github.com/kumose/jieba)
    * [Jieba GitHub python](https://github.com/fxsjy/jieba)
- **Language:** C++ / Python

## Overview

Jieba is a **high-performance Chinese word segmentation library** designed for **NLP preprocessing, search indexing, and text analytics**. It supports **dictionary-based, probabilistic, and HMM-driven segmentation**, allowing accurate tokenization for both **Simplified and Traditional Chinese**.

Jieba is primarily used in **offline or online NLP pipelines**, including search engines, recommendation systems, and content analysis tools. It is optimized for **speed and accuracy** over large-scale corpora while maintaining a **small memory footprint**.

---

## Key Features

* **Multiple segmentation modes:** Full mode, precise mode, and search engine mode.
* **Custom dictionary support:** Users can add domain-specific words and phrases.
* **HMM-based unknown word recognition:** Handles OOV (out-of-vocabulary) words using probabilistic modeling.
* **Unicode support:** Works with UTF-8 Chinese text, including mixed Simplified and Traditional input.
* **Extensible and easy to integrate:** Provides C++ API, Python bindings, and command-line tools.

---

## Typical Use Cases

* Preprocessing Chinese text for **NLP pipelines**.
* Tokenizing content for **search indexing** and query segmentation.
* Named entity recognition (NER) preprocessing.
* Real-time or batch **text analytics** for recommendation or content moderation.

---

## Industrial Fit

| Requirement                        | Jieba Support |
| ---------------------------------- | ------------- |
| Accurate Chinese word segmentation | ✔️            |
| Custom dictionary integration      | ✔️            |
| Unknown word handling (HMM)        | ✔️            |
| High-volume text processing        | ✔️            |
| Simplified / Traditional Chinese   | ✔️            |

---
