"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[1959],{2348:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"retrieve/vector/index","title":"Vector Search Library Selection Guide (Production-Ops Focused)","description":"1. Overview of Mainstream Open-Source Vector Search Libraries","source":"@site/i18n/zh-cn/docusaurus-plugin-content-docs/current/retrieve/vector/index.mdx","sourceDirName":"retrieve/vector","slug":"/retrieve/vector/","permalink":"/cppdev/zh-cn/docs/retrieve/vector/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Vector Search Library Selection Guide (Production-Ops Focused)","sidebar_label":"Library Selection"},"sidebar":"tutorialSidebar","previous":{"title":"CRoaring","permalink":"/cppdev/zh-cn/docs/retrieve/bitmap/roaring"},"next":{"title":"FAISS (Facebook AI Similarity Search) Overview","permalink":"/cppdev/zh-cn/docs/retrieve/vector/faiss"}}');var t=n(4848),s=n(8453);const l={title:"Vector Search Library Selection Guide (Production-Ops Focused)",sidebar_label:"Library Selection"},d=void 0,o={},c=[{value:"1. Overview of Mainstream Open-Source Vector Search Libraries",id:"1-overview-of-mainstream-open-source-vector-search-libraries",level:2},{value:"2. Scenario-Based Selection Recommendations (With Production Context)",id:"2-scenario-based-selection-recommendations-with-production-context",level:2},{value:"2.1 Lightweight Deployment (Edge / Small-Scale Datasets \u22645M Vectors)",id:"21-lightweight-deployment-edge--small-scale-datasets-5m-vectors",level:3},{value:"2.2 Medium-Scale On-Prem Deployment (5M~100M Vectors / CPU-Only)",id:"22-medium-scale-on-prem-deployment-5m100m-vectors--cpu-only",level:3},{value:"2.3 Large-Scale / SSD-Optimized Datasets (&gt;100M Vectors)",id:"23-large-scale--ssd-optimized-datasets-100m-vectors",level:3},{value:"2.4 GPU-Accelerated Low-Latency Retrieval",id:"24-gpu-accelerated-low-latency-retrieval",level:3},{value:"3. Real-Time CRUD Capability (Dynamic Index Updates)",id:"3-real-time-crud-capability-dynamic-index-updates",level:2},{value:"4. Key Selection Principles for Production",id:"4-key-selection-principles-for-production",level:2},{value:"5. Production Considerations",id:"5-production-considerations",level:2},{value:"GPU Usage",id:"gpu-usage",level:3},{value:"Multi-threading / OpenMP",id:"multi-threading--openmp",level:3},{value:"SIMD Usage",id:"simd-usage",level:3}];function a(e){const i={blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h2,{id:"1-overview-of-mainstream-open-source-vector-search-libraries",children:"1. Overview of Mainstream Open-Source Vector Search Libraries"}),"\n",(0,t.jsx)(i.p,{children:"This section lists production-proven C++ vector search libraries suitable for practical deployment, excluding academic-only, Python-only, or non-C++ libraries."}),"\n",(0,t.jsxs)(i.table,{children:[(0,t.jsx)(i.thead,{children:(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.th,{children:"Library Name"}),(0,t.jsx)(i.th,{children:"Core Developer"}),(0,t.jsx)(i.th,{children:"Core Strengths"}),(0,t.jsx)(i.th,{children:"Operational Complexity"}),(0,t.jsx)(i.th,{children:"Maintenance Status"})]})}),(0,t.jsxs)(i.tbody,{children:[(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"FAISS"}),(0,t.jsx)(i.td,{children:"Meta AI"}),(0,t.jsx)(i.td,{children:"Industrial standard, CPU/GPU hybrid support, multiple algorithms (PQ/IVF/HNSW), large-scale support"}),(0,t.jsx)(i.td,{children:"Medium (GPU tuning needed)"}),(0,t.jsx)(i.td,{children:"High (active updates, rich docs)"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"DiskANN"}),(0,t.jsx)(i.td,{children:"Microsoft"}),(0,t.jsx)(i.td,{children:"SSD-optimized, ultra-low RAM usage, disk-based large-scale storage"}),(0,t.jsx)(i.td,{children:"Medium (disk I/O tuning required)"}),(0,t.jsx)(i.td,{children:"Medium (stable updates, enterprise cases)"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"NMSLIB"}),(0,t.jsx)(i.td,{children:"Yandex"}),(0,t.jsx)(i.td,{children:"Stable CPU-only performance, multi-algorithm support"}),(0,t.jsx)(i.td,{children:"Low (plug-and-play)"}),(0,t.jsx)(i.td,{children:"Medium (mature, moderate updates)"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"NGT"}),(0,t.jsx)(i.td,{children:"Yahoo Japan"}),(0,t.jsx)(i.td,{children:"Native dynamic CRUD for small-scale datasets, high recall for high-dimensional data"}),(0,t.jsx)(i.td,{children:"Low (single-node only)"}),(0,t.jsx)(i.td,{children:"Medium (stable for dynamic scenarios)"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"HNSWLIB"}),(0,t.jsx)(i.td,{children:"C++"}),(0,t.jsx)(i.td,{children:"HNSW, incremental add & delete"}),(0,t.jsx)(i.td,{children:"Low"}),(0,t.jsx)(i.td,{children:"High (active, production-proven)"})]})]})]}),"\n",(0,t.jsxs)(i.blockquote,{children:["\n",(0,t.jsx)(i.p,{children:"Removed non-C++ or non-production libraries: Spotify Annoy, Weaviate, SPTAG, SCANN, Vespa.ai, RAFT."}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"2-scenario-based-selection-recommendations-with-production-context",children:"2. Scenario-Based Selection Recommendations (With Production Context)"}),"\n",(0,t.jsx)(i.h3,{id:"21-lightweight-deployment-edge--small-scale-datasets-5m-vectors",children:"2.1 Lightweight Deployment (Edge / Small-Scale Datasets \u22645M Vectors)"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Core Requirements"}),": Zero-dependency integration, minimal footprint, real-time dynamic updates"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Primary Recommendation"}),": HNSWLIB"]}),"\n",(0,t.jsx)(i.li,{children:"Production Fit: Single-node, supports incremental addition and deletion, ideal for \u22645M vectors."}),"\n",(0,t.jsx)(i.li,{children:"Ops Note: Batch updates recommended to reduce index fragmentation; best for dynamic CRUD."}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Alternative"}),": NGT"]}),"\n",(0,t.jsx)(i.li,{children:"Production Fit: Supports partial incremental insertions, deletion limited; single-node."}),"\n",(0,t.jsx)(i.li,{children:"Ops Note: Not ideal for high-frequency updates; still requires batch writes for stability."}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"22-medium-scale-on-prem-deployment-5m100m-vectors--cpu-only",children:"2.2 Medium-Scale On-Prem Deployment (5M~100M Vectors / CPU-Only)"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Core Requirements"}),": Stable single-node performance, memory-efficient storage"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Primary Recommendation"}),": FAISS (CPU)"]}),"\n",(0,t.jsxs)(i.li,{children:["Production Fit: ",(0,t.jsx)(i.code,{children:"IndexIVFPQ"})," for memory-efficient storage; suitable for up to ~100M vectors at 768-dim."]}),"\n",(0,t.jsx)(i.li,{children:"Ops Note: Incremental additions possible for very small batches; deletion requires rebuild or soft delete strategy."}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Alternative"}),": NMSLIB"]}),"\n",(0,t.jsx)(i.li,{children:"Production Fit: CPU-only HNSW; reliable and easy to maintain for medium-scale datasets."}),"\n",(0,t.jsx)(i.li,{children:"Ops Note: No native incremental deletion; static index preferred for consistent performance."}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"23-large-scale--ssd-optimized-datasets-100m-vectors",children:"2.3 Large-Scale / SSD-Optimized Datasets (>100M Vectors)"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Core Requirements"}),": Disk-backed storage, ultra-low RAM, static or batch-updated indices"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Primary Recommendation"}),": DiskANN"]}),"\n",(0,t.jsx)(i.li,{children:"Production Fit: Supports 100M\u20131B+ vectors with minimal RAM; HNSW on SSD for high recall."}),"\n",(0,t.jsx)(i.li,{children:"Ops Note: Batch-only updates; not suitable for real-time CRUD."}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Alternative"}),": FAISS (Distributed CPU)"]}),"\n",(0,t.jsxs)(i.li,{children:["Production Fit: Shard data across nodes; use ",(0,t.jsx)(i.code,{children:"IndexIVFPQ"})," or IVF-PQ for large-scale deployment."]}),"\n",(0,t.jsx)(i.li,{children:"Ops Note: Requires shared storage for index synchronization; higher ops overhead than DiskANN."}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"24-gpu-accelerated-low-latency-retrieval",children:"2.4 GPU-Accelerated Low-Latency Retrieval"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Core Requirements"}),": Sub-millisecond query latency, high throughput"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Primary Recommendation"}),": FAISS (GPU)"]}),"\n",(0,t.jsxs)(i.li,{children:["Production Fit: ",(0,t.jsx)(i.code,{children:"GpuIndexHNSW"})," ",(0,t.jsx)(i.code,{children:"<0.5ms"})," latency for ~100M vectors (768-dim); single GPU can handle 10k+ QPS."]}),"\n",(0,t.jsx)(i.li,{children:"Ops Note: Monitor VRAM to prevent OOM; suitable for read-heavy workloads."}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"3-real-time-crud-capability-dynamic-index-updates",children:"3. Real-Time CRUD Capability (Dynamic Index Updates)"}),"\n",(0,t.jsxs)(i.table,{children:[(0,t.jsx)(i.thead,{children:(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.th,{children:"Library"}),(0,t.jsx)(i.th,{children:"Incremental Add"}),(0,t.jsx)(i.th,{children:"Incremental Delete"}),(0,t.jsx)(i.th,{children:"Notes"})]})}),(0,t.jsxs)(i.tbody,{children:[(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"HNSWLIB"}),(0,t.jsx)(i.td,{children:"Yes"}),(0,t.jsx)(i.td,{children:"Yes"}),(0,t.jsx)(i.td,{children:"Single-node; best for datasets \u22645M; batch writes recommended."})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"NGT"}),(0,t.jsx)(i.td,{children:"Partial"}),(0,t.jsx)(i.td,{children:"Limited"}),(0,t.jsx)(i.td,{children:"Supports incremental insertions; deletion restricted; single-node only."})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"FAISS"}),(0,t.jsx)(i.td,{children:"Limited"}),(0,t.jsx)(i.td,{children:"No"}),(0,t.jsx)(i.td,{children:"Only very small datasets (~0.5M) support incremental add; deletion requires rebuild."})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"DiskANN"}),(0,t.jsx)(i.td,{children:"No"}),(0,t.jsx)(i.td,{children:"No"}),(0,t.jsx)(i.td,{children:"Designed for static, large-scale, disk-based indices; real-time CRUD not supported."})]})]})]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"4-key-selection-principles-for-production",children:"4. Key Selection Principles for Production"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Prioritize C++ Ecosystem"}),": Keep integration simple, single-node deployment preferred for small teams."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Match Real-Time Needs"}),": Only HNSWLIB and NGT (limited) support dynamic CRUD; FAISS incremental add feasible for tiny datasets."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Scale Appropriately"}),": \u22645M vectors \u2192 HNSWLIB; 5M\u2013100M \u2192 FAISS CPU; >100M \u2192 DiskANN or distributed FAISS."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"GPU Acceleration"}),": Only for high-throughput, low-latency read-heavy scenarios."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Distributed Considerations"}),": Focus on single-node; distributed systems are combinations of single-node instances."]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"5-production-considerations",children:"5. Production Considerations"}),"\n",(0,t.jsxs)(i.p,{children:["In practice, most production vector search systems ",(0,t.jsx)(i.strong,{children:"do not rely solely on open-source libraries"}),". Instead, they are usually ",(0,t.jsx)(i.strong,{children:"adapted or extended from existing algorithms"})," to meet the requirements of ",(0,t.jsx)(i.strong,{children:"online real-time indexing, dynamic CRUD, and operational stability"}),". For example, ",(0,t.jsx)(i.strong,{children:"Kumo builds upon HNSW"}),", adding enhancements to fully support ",(0,t.jsx)(i.strong,{children:"online real-time indexing"})," while maintaining low operational overhead."]}),"\n",(0,t.jsxs)(i.p,{children:["That said, if production requirements are not extremely stringent, ",(0,t.jsx)(i.strong,{children:"selecting an open-source library is entirely reasonable"}),"."]}),"\n",(0,t.jsx)(i.h3,{id:"gpu-usage",children:"GPU Usage"}),"\n",(0,t.jsxs)(i.p,{children:["While GPUs theoretically accelerate vector computations, actual performance can be ",(0,t.jsx)(i.strong,{children:"limited by memory bandwidth and CPU-GPU transfer speeds"}),". Benchmarking under realistic workloads is critical before committing to GPU deployment."]}),"\n",(0,t.jsx)(i.h3,{id:"multi-threading--openmp",children:"Multi-threading / OpenMP"}),"\n",(0,t.jsxs)(i.p,{children:["Multi-threading can improve throughput, but ",(0,t.jsx)(i.strong,{children:"thread-switching overhead may negate speedups"})," beyond a certain threshold. ",(0,t.jsx)(i.strong,{children:"OpenMP benchmarks"})," should be performed to identify the optimal parallelism level."]}),"\n",(0,t.jsx)(i.h3,{id:"simd-usage",children:"SIMD Usage"}),"\n",(0,t.jsxs)(i.p,{children:["SIMD instructions can increase computation speed but may ",(0,t.jsx)(i.strong,{children:"reduce numerical precision"}),", causing slight errors in distance or aggregation calculations. In ",(0,t.jsx)(i.strong,{children:"e-commerce scenarios"}),", even small precision loss can impact ranking or pricing computations. Validate precision impacts carefully before enabling aggressive SIMD optimizations."]})]})}function h(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>l,x:()=>d});var r=n(6540);const t={},s=r.createContext(t);function l(e){const i=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function d(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),r.createElement(s.Provider,{value:i},e.children)}}}]);