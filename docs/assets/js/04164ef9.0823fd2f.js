"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[1088],{8453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>l});var s=i(6540);const r={},t=s.createContext(r);function d(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),s.createElement(t.Provider,{value:n},e.children)}},8793:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>d,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"retrieve/nlp/jieba","title":"Jieba \u2013 Chinese Word Segmentation","description":"- Project:","source":"@site/docs/retrieve/nlp/jieba.mdx","sourceDirName":"retrieve/nlp","slug":"/retrieve/nlp/jieba","permalink":"/cppdev/docs/retrieve/nlp/jieba","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Hadar \u2013 Chinese Simplified/Traditional Conversion","permalink":"/cppdev/docs/retrieve/nlp/hadar"},"next":{"title":"SentencePiece \u2013 Subword Tokenization","permalink":"/cppdev/docs/retrieve/nlp/sentencepiece"}}');var r=i(4848),t=i(8453);const d={},l="Jieba \u2013 Chinese Word Segmentation",o={},a=[{value:"Overview",id:"overview",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Typical Use Cases",id:"typical-use-cases",level:2},{value:"Industrial Fit",id:"industrial-fit",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"jieba--chinese-word-segmentation",children:"Jieba \u2013 Chinese Word Segmentation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Project:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/kumose/jieba",children:"Jieba GitHub"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/fxsjy/jieba",children:"Jieba GitHub python"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Language:"})," C++ / Python"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsxs)(n.p,{children:["Jieba is a ",(0,r.jsx)(n.strong,{children:"high-performance Chinese word segmentation library"})," designed for ",(0,r.jsx)(n.strong,{children:"NLP preprocessing, search indexing, and text analytics"}),". It supports ",(0,r.jsx)(n.strong,{children:"dictionary-based, probabilistic, and HMM-driven segmentation"}),", allowing accurate tokenization for both ",(0,r.jsx)(n.strong,{children:"Simplified and Traditional Chinese"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Jieba is primarily used in ",(0,r.jsx)(n.strong,{children:"offline or online NLP pipelines"}),", including search engines, recommendation systems, and content analysis tools. It is optimized for ",(0,r.jsx)(n.strong,{children:"speed and accuracy"})," over large-scale corpora while maintaining a ",(0,r.jsx)(n.strong,{children:"small memory footprint"}),"."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multiple segmentation modes:"})," Full mode, precise mode, and search engine mode."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Custom dictionary support:"})," Users can add domain-specific words and phrases."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"HMM-based unknown word recognition:"})," Handles OOV (out-of-vocabulary) words using probabilistic modeling."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Unicode support:"})," Works with UTF-8 Chinese text, including mixed Simplified and Traditional input."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Extensible and easy to integrate:"})," Provides C++ API, Python bindings, and command-line tools."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"typical-use-cases",children:"Typical Use Cases"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Preprocessing Chinese text for ",(0,r.jsx)(n.strong,{children:"NLP pipelines"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Tokenizing content for ",(0,r.jsx)(n.strong,{children:"search indexing"})," and query segmentation."]}),"\n",(0,r.jsx)(n.li,{children:"Named entity recognition (NER) preprocessing."}),"\n",(0,r.jsxs)(n.li,{children:["Real-time or batch ",(0,r.jsx)(n.strong,{children:"text analytics"})," for recommendation or content moderation."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"industrial-fit",children:"Industrial Fit"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Requirement"}),(0,r.jsx)(n.th,{children:"Jieba Support"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Accurate Chinese word segmentation"}),(0,r.jsx)(n.td,{children:"\u2714\ufe0f"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Custom dictionary integration"}),(0,r.jsx)(n.td,{children:"\u2714\ufe0f"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Unknown word handling (HMM)"}),(0,r.jsx)(n.td,{children:"\u2714\ufe0f"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"High-volume text processing"}),(0,r.jsx)(n.td,{children:"\u2714\ufe0f"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Simplified / Traditional Chinese"}),(0,r.jsx)(n.td,{children:"\u2714\ufe0f"})]})]})]}),"\n",(0,r.jsx)(n.hr,{})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);