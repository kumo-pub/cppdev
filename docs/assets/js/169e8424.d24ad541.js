"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7686],{8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>o});var t=r(6540);const s={},i=t.createContext(s);function a(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(i.Provider,{value:n},e.children)}},9183:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"store/format/ocr","title":"OCR Format Overview","description":"OCR (Optical Character Recognition) data formats are used to store scanned document content, often including both the raw image and extracted text/annotations.","source":"@site/docs/store/format/ocr.mdx","sourceDirName":"store/format","slug":"/store/format/ocr","permalink":"/cppdev/docs/store/format/ocr","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"HDF5 Format Overview","permalink":"/cppdev/docs/store/format/hdf5"},"next":{"title":"NumPy Format Overview (.npy / .npz)","permalink":"/cppdev/docs/store/format/npy"}}');var s=r(4848),i=r(8453);const a={},o="OCR Format Overview",c={},l=[{value:"1. Key Characteristics",id:"1-key-characteristics",level:2},{value:"2. Usage Scenarios",id:"2-usage-scenarios",level:2},{value:"3. Popular OCR Data Formats",id:"3-popular-ocr-data-formats",level:2},{value:"4. Integration in Kumo",id:"4-integration-in-kumo",level:2},{value:"5. Performance Notes",id:"5-performance-notes",level:2},{value:"6. Useful Links",id:"6-useful-links",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"ocr-format-overview",children:"OCR Format Overview"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"OCR (Optical Character Recognition) data formats"})," are used to store scanned document content, often including both the raw image and extracted text/annotations.\nThese formats are widely used in document digitization, search indexing, and automated processing pipelines."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"1-key-characteristics",children:"1. Key Characteristics"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Image + Text Storage"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"OCR data typically combines the original image (TIFF, PNG, JPEG) with text results."}),"\n",(0,s.jsx)(n.li,{children:"Text may be stored with positional metadata (bounding boxes, coordinates), allowing precise mapping back to the source image."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Structured Annotations"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Modern OCR frameworks often store results in JSON, XML, or proprietary formats."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Annotations can include:"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Recognized text"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Confidence scores"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Word/line/page bounding boxes"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Language or font hints"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Hierarchical Organization"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Documents can have multiple pages, each with multiple regions or blocks of text."}),"\n",(0,s.jsx)(n.li,{children:"This hierarchical structure enables efficient search and retrieval of text in large documents."}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"2-usage-scenarios",children:"2. Usage Scenarios"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Document Digitization"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Converting scanned documents to searchable PDFs or text archives."}),"\n",(0,s.jsx)(n.li,{children:"Storing both the original image and extracted content for verification."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Search Indexing"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Index OCR results for full-text search in document management systems."}),"\n",(0,s.jsx)(n.li,{children:"Positional data allows highlighting and annotation features."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Data Extraction"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Extract structured information (invoices, receipts, forms) using OCR results."}),"\n",(0,s.jsx)(n.li,{children:"Combine with NLP or entity recognition pipelines."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Machine Learning Training"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"OCR datasets are often used to train models for text detection and recognition."}),"\n",(0,s.jsx)(n.li,{children:"Annotation formats like COCO-Text, ICDAR, or PAGE XML are standard."}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"3-popular-ocr-data-formats",children:"3. Popular OCR Data Formats"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Format"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Official Link / Notes"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"PAGE XML"})}),(0,s.jsx)(n.td,{children:"XML-based standard storing page layout, text, and metadata"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"https://www.primaresearch.org/page/page-xml",children:"https://www.primaresearch.org/page/page-xml"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"HOCR"})}),(0,s.jsx)(n.td,{children:"HTML-based format for OCR results, storing word positions and confidence"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"https://github.com/tmbdev/hocr-spec",children:"https://github.com/tmbdev/hocr-spec"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"ALTO XML"})}),(0,s.jsx)(n.td,{children:"XML format for OCR results, widely used in libraries and archives"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"https://www.loc.gov/standards/alto/",children:"https://www.loc.gov/standards/alto/"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"JSON"})}),(0,s.jsx)(n.td,{children:"Custom or framework-specific JSON annotations"}),(0,s.jsx)(n.td,{children:"e.g., Tesseract output, Google Vision OCR API"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"4-integration-in-kumo",children:"4. Integration in Kumo"}),"\n",(0,s.jsx)(n.p,{children:"In Kumo Stack, OCR data formats are typically used for:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Storing and indexing scanned documents for search"}),"\n",(0,s.jsx)(n.li,{children:"Supporting positional text highlighting in search results"}),"\n",(0,s.jsx)(n.li,{children:"Feeding downstream pipelines (NLP, classification, entity extraction)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Integration considerations:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Choose a format compatible with your OCR engine (Tesseract, Google Vision, AWS Textract, etc.)"}),"\n",(0,s.jsx)(n.li,{children:"Maintain mapping between original images and extracted text"}),"\n",(0,s.jsx)(n.li,{children:"Consider compression and storage for large document archives (e.g., zipped images + JSON/XML)"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"5-performance-notes",children:"5. Performance Notes"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"I/O Efficiency"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Storing text separately from images allows faster search and indexing"}),"\n",(0,s.jsx)(n.li,{children:"Large image archives benefit from block storage or cloud object storage"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Data Size Considerations"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"OCR output is usually small relative to raw images"}),"\n",(0,s.jsx)(n.li,{children:"Use binary XML or compressed JSON to reduce disk footprint"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parallel Processing"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Multi-page documents or large collections can be processed in parallel per page or region"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"6-useful-links",children:"6. Useful Links"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["PAGE XML: ",(0,s.jsx)(n.a,{href:"https://www.primaresearch.org/page/page-xml",children:"https://www.primaresearch.org/page/page-xml"})]}),"\n",(0,s.jsxs)(n.li,{children:["HOCR Specification: ",(0,s.jsx)(n.a,{href:"https://github.com/tmbdev/hocr-spec",children:"https://github.com/tmbdev/hocr-spec"})]}),"\n",(0,s.jsxs)(n.li,{children:["ALTO XML: ",(0,s.jsx)(n.a,{href:"https://www.loc.gov/standards/alto/",children:"https://www.loc.gov/standards/alto/"})]}),"\n",(0,s.jsxs)(n.li,{children:["Tesseract OCR: ",(0,s.jsx)(n.a,{href:"https://tesseract-ocr.github.io/",children:"https://tesseract-ocr.github.io/"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);