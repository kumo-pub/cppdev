"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[6007],{8220:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"store/format/parquet","title":"Parquet Format Overview","description":"Apache Parquet is a widely used open-source columnar storage file format designed for efficient data analytics.","source":"@site/docs/store/format/parquet.mdx","sourceDirName":"store/format","slug":"/store/format/parquet","permalink":"/cppdev/docs/store/format/parquet","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Data Formats Overview","permalink":"/cppdev/docs/store/format/"},"next":{"title":"HDF5 Format Overview","permalink":"/cppdev/docs/store/format/hdf5"}}');var t=n(4848),i=n(8453);const a={},l="Parquet Format Overview",c={},o=[{value:"1. Key Characteristics",id:"1-key-characteristics",level:2},{value:"2. Usage Scenarios",id:"2-usage-scenarios",level:2},{value:"3. Integration in Kumo",id:"3-integration-in-kumo",level:2},{value:"4. Performance Notes",id:"4-performance-notes",level:2},{value:"5. Useful Links",id:"5-useful-links",level:2}];function d(e){const r={a:"a",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.header,{children:(0,t.jsx)(r.h1,{id:"parquet-format-overview",children:"Parquet Format Overview"})}),"\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Apache Parquet"})," is a widely used open-source columnar storage file format designed for efficient data analytics.\nIt was created to work well with the Hadoop ecosystem and has since become a de-facto standard for analytical workloads across many platforms."]}),"\n",(0,t.jsx)(r.p,{children:"Official documentation:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["Apache Parquet Project: ",(0,t.jsx)(r.a,{href:"https://parquet.apache.org/",children:"https://parquet.apache.org/"})]}),"\n",(0,t.jsxs)(r.li,{children:["Parquet Format Specification: ",(0,t.jsx)(r.a,{href:"https://parquet.apache.org/documentation/latest/",children:"https://parquet.apache.org/documentation/latest/"})]}),"\n",(0,t.jsxs)(r.li,{children:["Parquet on GitHub: ",(0,t.jsx)(r.a,{href:"https://github.com/apache/parquet-format",children:"https://github.com/apache/parquet-format"})]}),"\n"]}),"\n",(0,t.jsx)(r.hr,{}),"\n",(0,t.jsx)(r.h2,{id:"1-key-characteristics",children:"1. Key Characteristics"}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Columnar Storage"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Parquet stores data column by column, not row by row."}),"\n",(0,t.jsx)(r.li,{children:"This enables reading only the necessary columns, reducing I/O for analytical queries."}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Schema-aware Metadata"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Each Parquet file includes its schema and metadata, allowing complex nested types (lists, structs, maps)."}),"\n",(0,t.jsx)(r.li,{children:"Schema information enables predicate pushdown and improved pruning."}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Per-column Encoding and Compression"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Each column can use different encoding/compression schemes, such as Snappy, Gzip, Brotli, or ZSTD."}),"\n",(0,t.jsx)(r.li,{children:"Columnar compression is more efficient than row-based compression for analytical workloads."}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Splittable Files"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Large Parquet files can be split across multiple processing tasks, enabling parallel reads."}),"\n"]}),"\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Cross-language Interoperability"}),"\nParquet is supported in many ecosystems:"]}),"\n",(0,t.jsxs)(r.table,{children:[(0,t.jsx)(r.thead,{children:(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.th,{children:"Language"}),(0,t.jsx)(r.th,{children:"API / Library"})]})}),(0,t.jsxs)(r.tbody,{children:[(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"Java"}),(0,t.jsx)(r.td,{children:"Apache Parquet (native)"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"C++"}),(0,t.jsx)(r.td,{children:"Apache Arrow / Parquet C++"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"Python"}),(0,t.jsx)(r.td,{children:"pyarrow, fastparquet"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"Go"}),(0,t.jsx)(r.td,{children:"parquet-go"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"Rust"}),(0,t.jsx)(r.td,{children:"parquet-rs"})]})]})]}),"\n",(0,t.jsx)(r.hr,{}),"\n",(0,t.jsx)(r.h2,{id:"2-usage-scenarios",children:"2. Usage Scenarios"}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Analytical Workloads"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Aggregations, reporting, BI queries over large datasets"}),"\n",(0,t.jsx)(r.li,{children:"Time-series analytics and OLAP queries"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Cloud Data Lakes"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Preferred format for object store data in AWS S3, GCS, Azure Blob"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Data Interchange"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Works natively with Spark, Presto, Hive, Trino, Flink"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Batch Processing"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Best for batch or append-heavy workloads, not random KV updates"}),"\n"]}),"\n",(0,t.jsx)(r.hr,{}),"\n",(0,t.jsx)(r.h2,{id:"3-integration-in-kumo",children:"3. Integration in Kumo"}),"\n",(0,t.jsx)(r.p,{children:"In Kumo Stack, Parquet is typically used for:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Storing large structured datasets"}),"\n",(0,t.jsx)(r.li,{children:"Batch export/import pipelines"}),"\n",(0,t.jsx)(r.li,{children:"Persistence of analysis results"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"Integration considerations:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Use schema evolution best practices \u2014 adding columns or optional fields carefully"}),"\n",(0,t.jsx)(r.li,{children:"Prefer larger Parquet files (\u2265256 MB) to reduce overhead"}),"\n",(0,t.jsx)(r.li,{children:"Use predicate pushdown to minimize data read"}),"\n"]}),"\n",(0,t.jsx)(r.hr,{}),"\n",(0,t.jsx)(r.h2,{id:"4-performance-notes",children:"4. Performance Notes"}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"I/O Efficiency"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Reading selected columns reduces disk I/O significantly"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Compression"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Column-wise compression achieves higher ratios than row-based formats"}),"\n",(0,t.jsx)(r.li,{children:"Compression choice should balance CPU cost vs storage savings"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Parallel Reads"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Large files allow distributed processing systems to read different row groups in parallel"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Example Workflow"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"ETL pipeline writes daily Parquet partitions"}),"\n",(0,t.jsx)(r.li,{children:"Analytics engine reads only relevant columns"}),"\n",(0,t.jsx)(r.li,{children:"Predicate pushdown filters rows without scanning the full file"}),"\n"]}),"\n",(0,t.jsx)(r.hr,{}),"\n",(0,t.jsx)(r.h2,{id:"5-useful-links",children:"5. Useful Links"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["Apache Parquet Official: ",(0,t.jsx)(r.a,{href:"https://parquet.apache.org/",children:"https://parquet.apache.org/"})]}),"\n",(0,t.jsxs)(r.li,{children:["Parquet Documentation: ",(0,t.jsx)(r.a,{href:"https://parquet.apache.org/documentation/latest/",children:"https://parquet.apache.org/documentation/latest/"})]}),"\n",(0,t.jsxs)(r.li,{children:["GitHub: ",(0,t.jsx)(r.a,{href:"https://github.com/apache/parquet-format",children:"https://github.com/apache/parquet-format"})]}),"\n",(0,t.jsxs)(r.li,{children:["Parquet with Spark: ",(0,t.jsx)(r.a,{href:"https://spark.apache.org/docs/latest/sql-data-sources-parquet.html",children:"https://spark.apache.org/docs/latest/sql-data-sources-parquet.html"})]}),"\n",(0,t.jsxs)(r.li,{children:["Parquet with Python (pyarrow): ",(0,t.jsx)(r.a,{href:"https://arrow.apache.org/docs/python/parquet.html",children:"https://arrow.apache.org/docs/python/parquet.html"})]}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>a,x:()=>l});var s=n(6540);const t={},i=s.createContext(t);function a(e){const r=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(i.Provider,{value:r},e.children)}}}]);