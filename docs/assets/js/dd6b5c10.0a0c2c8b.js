"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7300],{8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>l});var t=s(6540);const r={},i=t.createContext(r);function o(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(i.Provider,{value:n},e.children)}},9032:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>a});const t=JSON.parse('{"id":"store/cloud/hdfs","title":"HDFS Integration","description":"This document describes how to integrate HDFS using libhdfs3 into a Kumo deployment.","source":"@site/docs/store/cloud/hdfs.mdx","sourceDirName":"store/cloud","slug":"/store/cloud/hdfs","permalink":"/cppdev/docs/store/cloud/hdfs","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"HDFS Integration"},"sidebar":"tutorialSidebar","previous":{"title":"Google Cloud Storage Integration","permalink":"/cppdev/docs/store/cloud/gcs"},"next":{"title":"Data Formats Overview","permalink":"/cppdev/docs/store/format/"}}');var r=s(4848),i=s(8453);const o={title:"HDFS Integration"},l="HDFS Integration with Kumo Stack",d={},a=[{value:"1. Supported HDFS Component via <code>kmpkg</code>",id:"1-supported-hdfs-component-via-kmpkg",level:2},{value:"2. Integration Patterns",id:"2-integration-patterns",level:2},{value:"2.1 KV Backup to HDFS",id:"21-kv-backup-to-hdfs",level:3},{value:"2.2 Operational Notes",id:"22-operational-notes",level:3},{value:"3. KV Layer Backup Strategy",id:"3-kv-layer-backup-strategy",level:2},{value:"4. Example Workflow",id:"4-example-workflow",level:2},{value:"5. Summary",id:"5-summary",level:2}];function c(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"hdfs-integration-with-kumo-stack",children:"HDFS Integration with Kumo Stack"})}),"\n",(0,r.jsxs)(n.p,{children:["This document describes ",(0,r.jsx)(n.strong,{children:"how to integrate HDFS using libhdfs3"})," into a Kumo deployment.\nFocus is on ",(0,r.jsx)(n.strong,{children:"practical integration and operational guidance"}),", not on choosing HDFS over other clouds."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.h2,{id:"1-supported-hdfs-component-via-kmpkg",children:["1. Supported HDFS Component via ",(0,r.jsx)(n.code,{children:"kmpkg"})]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Package"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"libhdfs3"}),(0,r.jsx)(n.td,{children:"Native C++ library to interact with HDFS, supports file read/write, directory listing, and permission management."})]})})]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["libhdfs3 is the recommended integration method for Kumo Stack due to its ",(0,r.jsx)(n.strong,{children:"performance, stability, and operational simplicity"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"2-integration-patterns",children:"2. Integration Patterns"}),"\n",(0,r.jsx)(n.h3,{id:"21-kv-backup-to-hdfs",children:"2.1 KV Backup to HDFS"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Use Cases:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Store RocksDB SST files or snapshots."}),"\n",(0,r.jsx)(n.li,{children:"Long-term retention and disaster recovery."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"single SST file uploads per RocksDB snapshot"})," to simplify restore."]}),"\n",(0,r.jsxs)(n.li,{children:["Organize ",(0,r.jsx)(n.strong,{children:"directory hierarchy by environment/date"}),":"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n/kv-backups/\n\u2514\u2500 rocksdb/\n\u2514\u2500 2026-01-04/\n\u251c\u2500 cf_default-00001.sst\n\u2514\u2500 cf_default-00002.sst\n\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"C++ Example: Upload SST to HDFS"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:'#include "hdfs/hdfs.h"\n\nhdfsFS fs = hdfsConnect("namenode-host", 8020);\nhdfsFile file = hdfsOpenFile(fs, "/kv-backups/rocksdb/snapshot-20260104.sst", O_WRONLY|O_CREAT, 0, 0, 0);\n\n// Write local SST file to HDFS\nchar buffer[64 * 1024];\nstd::ifstream in("snapshot.sst", std::ios::binary);\nwhile (in.read(buffer, sizeof(buffer))) {\n    hdfsWrite(fs, file, buffer, in.gcount());\n}\n\nhdfsCloseFile(fs, file);\nhdfsDisconnect(fs);\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"22-operational-notes",children:"2.2 Operational Notes"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Throughput:"})," Use multiple threads to upload large SST files concurrently."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Directory Organization:"})," Avoid too many files in a single directory; it degrades NameNode performance."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Permissions:"})," Ensure HDFS user has write access; recommended to run Kumo services under dedicated HDFS user."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Restore:"})," Always validate snapshot restore on staging before production use."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"3-kv-layer-backup-strategy",children:"3. KV Layer Backup Strategy"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RocksDB Snapshots:"})," Use ",(0,r.jsx)(n.code,{children:"DB::GetSnapshot()"})," to generate a consistent view."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Checkpoint API:"})," Copy full directory, then upload to HDFS."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Column Families:"})," Minimize CFs to reduce operational complexity."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"4-example-workflow",children:"4. Example Workflow"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Take RocksDB snapshot via ",(0,r.jsx)(n.code,{children:"rocksdb::DB::GetSnapshot()"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Flush required column families."}),"\n",(0,r.jsx)(n.li,{children:"Save SST files locally."}),"\n",(0,r.jsx)(n.li,{children:"Upload SST files to HDFS using libhdfs3."}),"\n",(0,r.jsx)(n.li,{children:"Optionally trigger downstream validation/notification."}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"5-summary",children:"5. Summary"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kumo HDFS integration focuses on ",(0,r.jsx)(n.strong,{children:"operational-first design"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"single SST uploads, organized directories"}),", and ",(0,r.jsx)(n.strong,{children:"minimal CFs"})," for maintainable backups."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"libhdfs3"})," provides a ",(0,r.jsx)(n.strong,{children:"native, high-performance, C++ compatible interface"})," for KV backup and snapshot workflows."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);